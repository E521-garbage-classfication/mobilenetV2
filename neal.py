import os
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'  # GPU è¨˜æ†¶é«”å¯å‹•æ…‹æˆé•·
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'          # é—œé–‰ TensorFlow è­¦å‘Šè¨Šæ¯
import glob
import tensorflow as tf
from tensorflow.keras import layers, models, regularizers
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
from datetime import datetime
import sys
sys.stdout.flush()

# GPU ç’°å¢ƒåµæ¸¬èˆ‡æç¤º
# è‹¥æœªåµæ¸¬åˆ° GPU å‰‡æœƒè‡ªå‹•æ”¹ç”¨ CPU
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    print("âœ… GPU is available and being used:", gpus)
else:
    print("âŒ No GPU detected. Using CPU.")

# è¨“ç·´èˆ‡å„²å­˜ç›¸é—œè³‡æ–™å¤¾è¨­å®š
model_dir = r'C:\E521C\saved_models_v2_new'
os.makedirs(model_dir, exist_ok = True)  # è‹¥è³‡æ–™å¤¾ä¸å­˜åœ¨å‰‡å»ºç«‹
count_path = os.path.join(model_dir, 'train_count.txt')  # ç´€éŒ„è¨“ç·´æ¬¡æ•¸çš„æª”æ¡ˆ

# è¨“ç·´æ¬¡æ•¸ç´¯åŠ é‚è¼¯
if os.path.exists(count_path):
    with open(count_path, 'r') as f:
        count = int(f.read().strip()) + 1
else:
    count = 1
with open(count_path, 'w') as f:
    f.write(str(count))

print(f"ðŸ§  Training No.{count}", flush = True)

# è¼‰å…¥è³‡æ–™é›†
# è‡ªè³‡æ–™å¤¾ä¸­è‡ªå‹•ä¾ç…§å­è³‡æ–™å¤¾åˆ†é¡žé€²è¡Œæ¨™è¨˜ï¼Œä¸¦åˆ‡åˆ†ç‚ºè¨“ç·´é›†èˆ‡é©—è­‰é›†
data_dir = r'C:\E521C\DataImage\trash_dataset_v2_new'
class_names = sorted([folder for folder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, folder))])
num_classes = len(class_names)

# ä½¿ç”¨ MobileNetV2 çš„é è™•ç†å‡½æ•¸é€²è¡Œè³‡æ–™å¢žå¼·åŠé è™•ç†
train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split = 0.2,  # é©—è­‰é›†æ¯”ä¾‹ç‚º 20%
    subset = "both",
    seed = 123,              # éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿æ¯æ¬¡åˆ‡å‰²ä¸€è‡´
    image_size = (128, 128),
    batch_size = 16,         # è¨“ç·´æ¯æ¬¡æ‰¹é‡å¤§å°
    label_mode='int',
    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input  # ä½¿ç”¨é è™•ç†å‡½æ•¸
)

# å½±åƒå¢žå¼·ï¼ˆè¨“ç·´é›†ç”¨ï¼‰
augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),     # éš¨æ©Ÿå·¦å³ç¿»è½‰
    layers.RandomRotation(0.2),          # éš¨æ©Ÿæ—‹è½‰ Â±20%
    layers.RandomZoom(0.2),              # éš¨æ©Ÿæ”¾å¤§/ç¸®å°
    layers.RandomContrast(0.1),          # éš¨æ©Ÿå°æ¯”åº¦ Â±10%
    layers.RandomTranslation(0.1, 0.1)   # éš¨æ©Ÿå¹³ç§»
])

# å¥—ç”¨é è™•ç†æµç¨‹ï¼šè¨“ç·´é›†ä½¿ç”¨å¢žå¼·ï¼Œé©—è­‰é›†ä¸ä½¿ç”¨å¢žå¼·
train_ds = train_ds.map(lambda x, y: (augmentation(x), y))  # åªå°è¨“ç·´é›†é€²è¡Œå¢žå¼·

# åŠ å…¥é æŠ“æ©Ÿåˆ¶ï¼ˆåŠ å¿«è³‡æ–™åŠ è¼‰ï¼‰
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(buffer_size = AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size = AUTOTUNE)

# æ¨¡åž‹å„²å­˜è·¯å¾‘
h5_path = os.path.join(model_dir, 'trash_model_advanced.h5')
keras_path = os.path.join(model_dir, 'trash_model_advanced.keras')

# å»ºç«‹æ¨¡åž‹å‡½æ•¸ï¼ˆå¯é‡è¤‡ä½¿ç”¨ï¼‰
def build_model():
    base_model = MobileNetV2(input_shape = (128, 128, 3), include_top = False, weights = 'imagenet')  # ä½¿ç”¨é è¨“ç·´æ¬Šé‡
    base_model.trainable = True
    for layer in base_model.layers[:100]:      # å‡çµå‰ 100 å±¤ï¼Œåªå¾®èª¿æœ€å¾Œå¹¾å±¤
        layer.trainable = False

    model = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(256, activation = 'relu', kernel_regularizer = regularizers.l2(1e-4)),  # L2 æ­£å‰‡åŒ–ï¼Œé¿å…éŽæ“¬åˆ
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.l2(1e-4)),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation = 'softmax')  
    ])
    return model

# è¼‰å…¥æ¨¡åž‹ï¼ˆè‹¥æœ‰èˆŠæ¨¡åž‹å¯ç¹¼çºŒè¨“ç·´ï¼‰
try:
    if os.path.exists(h5_path):
        print("âœ… Found .h5 model, continue training...", flush = True)
        model = load_model(h5_path)
    elif os.path.exists(keras_path):
        print("ðŸ§ª Found .keras model, converting to .h5...", flush = True)
        model = load_model(keras_path)
        model.save(h5_path)
        print("âœ… Conversion complete, using .h5 model.", flush = True)
    else:
        raise FileNotFoundError
except Exception as e:
    print("âŒ Error loading model:", e, flush = True)
    print("ðŸ”ƒ Creating new model...", flush = True)
    model = build_model()

# âœ… ç·¨è­¯æ¨¡åž‹ï¼šæŒ‡å®š optimizerã€loss å‡½æ•¸èˆ‡è©•ä¼°æŒ‡æ¨™
model.compile(
    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4),  # åˆå§‹å­¸ç¿’çŽ‡
    loss = 'sparse_categorical_crossentropy',  # æ­é…æ•´æ•¸æ¨™ç±¤ä½¿ç”¨
    metrics = ['accuracy']
)

# è¨“ç·´æ¨¡åž‹ï¼ˆEarlyStopping + ReduceLROnPlateau æŽ§åˆ¶è¨“ç·´ï¼‰
early_stop = EarlyStopping(monitor = 'val_accuracy', patience = 5, restore_best_weights = True)  
reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.5, patience = 3, min_lr = 1e-6, verbose = 1)  # é™ä½Žå­¸ç¿’çŽ‡
print("Start training", flush = True)
history = model.fit(train_ds, validation_data = val_ds, epochs = 50, callbacks = [early_stop, reduce_lr], verbose = 2)
print("End of training", flush = True)

# ï¼ˆFine-tuningï¼‰ï¼šè§£å‡æ›´å¤šå±¤åšé€²ä¸€æ­¥å­¸ç¿’
# ç¬¬äºŒéšŽæ®µå¾®èª¿
print(" Start fine-tuning phase 2 (unfreeze all layers)...", flush = True)
# ç¬¬äºŒéšŽæ®µ callbacksï¼šé¿å…æ²¿ç”¨å‰ä¸€éšŽæ®µçš„ callback ç‹€æ…‹
early_stop_fine = EarlyStopping(monitor = 'val_accuracy', patience = 5, restore_best_weights = True)
reduce_lr_fine = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.5, patience = 3, min_lr = 1e-6, verbose = 1)

model.layers[0].trainable = True  

# é‡æ–°ç·¨è­¯æ¨¡åž‹
model.compile(
    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5),  # æ›´å°å­¸ç¿’çŽ‡
    loss = 'sparse_categorical_crossentropy',
    metrics = ['accuracy']
)

# åŸ·è¡Œç¬¬äºŒè¼ªè¨“ç·´
history_fine = model.fit(train_ds, validation_data = val_ds, epochs = 10, callbacks = [early_stop_fine, reduce_lr_fine], verbose = 2)

# åˆä½µç¬¬äºŒéšŽæ®µè¨“ç·´ç´€éŒ„
for key in history.history:
    history.history[key].extend(history_fine.history[key])

print("âœ… Fine-tuning complete.", flush = True)

# å„²å­˜æ¨¡åž‹ï¼ˆä¸»æ¨¡åž‹èˆ‡å‚™ä»½æ¨¡åž‹ï¼‰
model.save(h5_path)
backup_model_path = os.path.join(model_dir, f'best_model_run{count}.h5')
model.save(backup_model_path)

# ä¿ç•™æœ€è¿‘ 3 å€‹æ¨¡åž‹ï¼Œå…¶é¤˜è‡ªå‹•åˆªé™¤ï¼ˆç¯€çœç©ºé–“ï¼‰
all_models = sorted(glob.glob(os.path.join(model_dir, "best_model_run*.h5")), key = os.path.getmtime)
if len(all_models) > 3:
    for old_model in all_models[:-3]:
        os.remove(old_model)

# ç¹ªè£½æº–ç¢ºçŽ‡æ›²ç·šåœ–ï¼ˆè¨“ç·´ vs é©—è­‰ï¼‰
plt.plot(history.history['accuracy'], label = 'Train Acc')
plt.plot(history.history['val_accuracy'], label = 'Val Acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title(f'Training vs Validation Accuracy - Run {count}')
plt.legend()
acc_plot_path = os.path.join(model_dir, f'train_plot_run{count}.png')
plt.savefig(acc_plot_path)
plt.show()

# ç¹ªè£½æå¤±å€¼æ›²ç·šåœ–ï¼ˆè¨“ç·´ vs é©—è­‰ï¼‰
plt.plot(history.history['loss'], label = 'Train Loss')
plt.plot(history.history['val_loss'], label = 'Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title(f'Training vs Validation Loss - Run {count}')
plt.legend()
loss_plot_path = os.path.join(model_dir, f'train_loss_run{count}.png')
plt.savefig(loss_plot_path)
plt.show()

# åœ–è¡¨éŽå¤šæ™‚è‡ªå‹•æ¸…ç†ï¼Œåªä¿ç•™ 15 å¼µ
# acc_plots = sorted(glob.glob(os.path.join(model_dir, "train_plot_run*.png")), key = os.path.getmtime)
# if len(acc_plots) > 15:
#     for old_plot in acc_plots[:-15]:
#         os.remove(old_plot)

# loss_plots = sorted(glob.glob(os.path.join(model_dir, "train_loss_run*.png")), key = os.path.getmtime)
# if len(loss_plots) > 15:
#     for old_plot in loss_plots[:-15]:
#         os.remove(old_plot)

# âœ… è¨“ç·´è¨˜éŒ„å¯«å…¥ log æª”æ¡ˆ
log_text = f"Run {count} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
log_text += f"Train Acc: {history.history['accuracy'][-1]:.4f} | Val Acc: {history.history['val_accuracy'][-1]:.4f}\n"
log_text += f"Train Loss: {history.history['loss'][-1]:.4f} | Val Loss: {history.history['val_loss'][-1]:.4f}\n"
log_text += f"Model Saved: {h5_path} and {backup_model_path}\n"
log_text += "-------------------------\n"

with open(os.path.join(model_dir, 'log.txt'), 'a', encoding = 'utf-8') as f:
    f.write(log_text)
